---
title: "CNN Example - Dogs vs Cats"
output:
  pdf_document: default
  html_notebook: default
---
References:

- [MXNet CNN Starter kit](https://www.kaggle.com/jeremiedb/mxnet-with-r-starter-kit)
- [Kaggle: Cats vs Dogs dataset](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)
- [Dataset Mirror](https://www.floydhub.com/fastai/datasets/kaggle-dogs-vs-cats-redux-kernels-edition)
- [R Markdown](http://rmarkdown.rstudio.com)


Setup:

```{r}
# install.packages(c("imager", "data.table", "dtplyr", "dplyr", "readr", "ggplot2", "plotly"))
```




```{r}
library(imager)
library(data.table)
library(dtplyr)
library(dplyr)
library(readr)
library(ggplot2)
library(plotly)
library(mxnet)
```
Input preprocessing
===================

Before starting we need to process the images, as they are not a standard 
data.frame. We first are required to build a list of filenames out of the images.

```{r}
# Load the MNIST digit recognition dataset into R
# http://yann.lecun.com/exdb/mnist/
# assume you have all 4 files and gunzip'd them
# creates train$n, train$x, train$y  and test$n, test$x, test$y
# e.g. train$x is a 60000 x 784 matrix, each row is one digit (28x28)
# call:  show_digit(train$x[5,])   to see a digit.
# brendan o'connor - gist.github.com/39760 - anyall.org

load_mnist <- function() {
  load_image_file <- function(filename) {
    ret = list()
    f = file(filename,'rb')
    readBin(f,'integer',n=1,size=4,endian='big')
    ret$n = readBin(f,'integer',n=1,size=4,endian='big')
    nrow = readBin(f,'integer',n=1,size=4,endian='big')
    ncol = readBin(f,'integer',n=1,size=4,endian='big')
    x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
    ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
    close(f)
    ret
  }
  load_label_file <- function(filename) {
    f = file(filename,'rb')
    readBin(f,'integer',n=1,size=4,endian='big')
    n = readBin(f,'integer',n=1,size=4,endian='big')
    y = readBin(f,'integer',n=n,size=1,signed=F)
    close(f)
    y
  }
  train <<- load_image_file('mnist/train-images-idx3-ubyte')
  test <<- load_image_file('mnist/t10k-images-idx3-ubyte')
  
  train$y <<- load_label_file('mnist/train-labels-idx1-ubyte')
  test$y <<- load_label_file('mnist/t10k-labels-idx1-ubyte')  
}


show_digit <- function(arr784, col=gray(12:1/12), ...) {
  image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
```

Image Loading
-------------

```{r}
  load_image_file <- function(filename) {
    ret = list()
    f = file(filename,'rb')
    readBin(f,'integer',n=1,size=4,endian='big')
    ret$n = readBin(f,'integer',n=1,size=4,endian='big')
    nrow = readBin(f,'integer',n=1,size=4,endian='big')
    ncol = readBin(f,'integer',n=1,size=4,endian='big')
    x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
    ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
    close(f)
    ret
  }

  load_label_file <- function(filename) {
    f = file(filename,'rb')
    readBin(f,'integer',n=1,size=4,endian='big')
    n = readBin(f,'integer',n=1,size=4,endian='big')
    y = readBin(f,'integer',n=n,size=1,signed=F)
    close(f)
    y
  }
  train <- load_image_file('~/data/fashionMNIST/train-images-idx3-ubyte')
  test <- load_image_file('~/data/fashionMNIST/t10k-images-idx3-ubyte')
  
  train$y <- load_label_file('~/data/fashionMNIST/train-labels-idx1-ubyte')
  test$y <- load_label_file('~/data/fashionMNIST/t10k-labels-idx1-ubyte') 
```

Reshape data for CNN input
--------------------------

As input data we have now a matrix of N rows times M columns. The rows represent
each image and the columns each pixel of the image. We will reshape it to take
the shape of a 4 dimensional array. First identifier will be the image, second 
the channel and third and fourth will be the coordinates of a given pixel of the
image.

Mind that as we are working with a grayscale image we only have one channel.

```{r}
train$x <- array(train$x, c(train$n,1,28,28))
train$x <- aperm(train$x, c(3,4,2,1))
test$x <- array(test$x, c(test$n,1,28,28))
test$x <- aperm(test$x, c(3,4,2,1))
```



Check images after preprocess
-----------------------------
```{r}
show_image <- function(imgarray, col=gray(12:1/12), ...) {
  image(matrix(imgarray, nrow=28)[,28:1], col=col, ...)
}

show_image(train$x[,,,13])

```

Model architecture definition
-----------------------------

Now we have to define the CNN architecture.

```{r}
# input
data <- mx.symbol.Variable('data')

conv1A <- mx.symbol.Convolution(data=data, kernel=c(3,3), num_filter=32, stride=c(1,1), pad=c(1,1))
act1A <- mx.symbol.Activation(data=conv1A, act_type="relu")
conv1B <- mx.symbol.Convolution(data=act1A, kernel=c(3,3), num_filter=32, stride=c(1,1), pad=c(1,1))
act1B <- mx.symbol.Activation(data=conv1B, act_type="relu")
pool1<- mx.symbol.Pooling(data=act1B, pool_type="max", kernel=c(2,2), stride=c(2,2), pad=c(0,0))

conv2A <- mx.symbol.Convolution(data=pool1, kernel=c(3,3), num_filter=64, stride=c(1,1), pad=c(1,1))
act2A <- mx.symbol.Activation(data=conv2A, act_type="relu")
conv2B <- mx.symbol.Convolution(data=act2A, kernel=c(3,3), num_filter=64, stride=c(1,1), pad=c(1,1))
act2B <- mx.symbol.Activation(data=conv2B, act_type="relu")
pool2<- mx.symbol.Pooling(data=act2B, pool_type="max", kernel=c(2,2), stride=c(2,2), pad=c(0,0))

conv3A <- mx.symbol.Convolution(data=pool2, kernel=c(3,3), num_filter=128, stride=c(1,1), pad=c(1,1))
act3A <- mx.symbol.Activation(data=conv3A, act_type="relu")
conv3B <- mx.symbol.Convolution(data=act3A, kernel=c(3,3), num_filter=128, stride=c(1,1), pad=c(1,1))
act3B <- mx.symbol.Activation(data=conv3B, act_type="relu")
pool3<- mx.symbol.Pooling(data=act3B, pool_type="max", kernel=c(2,2), stride=c(2,2), pad=c(0,0))

conv4A <- mx.symbol.Convolution(data=pool3, kernel=c(3,3), num_filter=128, stride=c(1,1), pad=c(1,1))
act4A <- mx.symbol.Activation(data=conv4A, act_type="relu")
conv4B <- mx.symbol.Convolution(data=act4A, kernel=c(3,3), num_filter=128, stride=c(1,1), pad=c(1,1))
act4B <- mx.symbol.Activation(data=conv4B, act_type="relu")
pool4<- mx.symbol.Pooling(data=act4B, pool_type="max", kernel=c(2,2), stride=c(2,2), pad=c(0,0))

# flatten
flatten <- mx.symbol.Flatten(data=pool4)

fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=512)
act_fc1 <- mx.symbol.Activation(data=fc1, act_type="relu")
drop1 <- mx.symbol.Dropout(data=act_fc1, p=0.5)

# loss
fc_final <- mx.symbol.FullyConnected(data=drop1, num_hidden=2)
convnet <- mx.symbol.SoftmaxOutput(data=fc_final)

### plot the model structure
graph.viz(convnet)

```

```{r}
# input
data <- mx.symbol.Variable('data')

conv1A <- mx.symbol.Convolution(data=data, kernel=c(3,3), num_filter=128, stride=c(1,1), pad=c(1,1))
act1A <- mx.symbol.Activation(data=conv1A, act_type="relu")
conv1B <- mx.symbol.Convolution(data=act1A, kernel=c(3,3), num_filter=128, stride=c(1,1), pad=c(1,1))
act1B <- mx.symbol.Activation(data=conv1B, act_type="relu")
pool1<- mx.symbol.Pooling(data=act1B, pool_type="max", kernel=c(2,2), stride=c(2,2), pad=c(0,0))

conv2A <- mx.symbol.Convolution(data=pool1, kernel=c(3,3), num_filter=64, stride=c(1,1), pad=c(1,1))
act2A <- mx.symbol.Activation(data=conv2A, act_type="relu")
conv2B <- mx.symbol.Convolution(data=act2A, kernel=c(3,3), num_filter=64, stride=c(1,1), pad=c(1,1))
act2B <- mx.symbol.Activation(data=conv2B, act_type="relu")
pool2<- mx.symbol.Pooling(data=act2B, pool_type="max", kernel=c(2,2), stride=c(2,2), pad=c(0,0))

# flatten
flatten <- mx.symbol.Flatten(data=pool2)

fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=512)
act_fc1 <- mx.symbol.Activation(data=fc1, act_type="relu")
drop1 <- mx.symbol.Dropout(data=act_fc1, p=0.05)

# loss
fc_final <- mx.symbol.FullyConnected(data=drop1, num_hidden=2)
convnet <- mx.symbol.SoftmaxOutput(data=fc_final)

### plot the model structure
graph.viz(convnet)

```


Model training
--------------

```{r}
devices <- mx.cpu()

### combine symbols and create executor for inspection of learned features
combined<- mx.symbol.Group(act1A, convnet)
executor <- mx.simple.bind(symbol=combined, data=dim(train$x), ctx=devices)

mx.set.seed(123)
model_mxnet <- mx.model.FeedForward.create(convnet,
                                               X=train$x, 
                                               y=train$y,
                                               eval.data = list(data=eval_array, label=eval_labels),
                                               array.batch.size = 16, 
                                               ctx=devices, 
                                               num.round=5,
                                               learning.rate=0.05,
                                               wd=0.001,
                                               momentum=0.1,
                                               clip_gradient=1,
                                               eval.metric=mx.metric.accuracy, 
                                               initializer=mx.init.Xavier(rnd_type = "gaussian", factor_type = "avg", magnitude = 3),
                                               epoch.end.callback = mx.callback.log.train.metric(1))

```


Looking at generated features
-----------------------------
```{r}
mx.exec.update.arg.arrays(exec = executor, arg.arrays = model_mxnet$arg.params, match.name=TRUE)
mx.exec.update.arg.arrays(executor, list(data=mx.nd.array(train_array)), match.name=TRUE)
mx.exec.forward(executor, is.train=FALSE)

par(mfrow=c(4,4), mar=c(0.1,0.1,0.1,0.1))
for (i in 1:16) {
  img_array <- as.array(executor$outputs$activation0_output)[,,i,1]
  img<-as.cimg(img_array)
  plot(img)
}
```

Generating predictions
----------------------

```{r}
pred_prob<- t(predict(model_mxnet, eval_array))
submit <- data.frame(id=1:64, label=pred_prob[, 2])
head(submit)
```

